{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0F2fy0Pqcd-"
      },
      "source": [
        "# Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfIlbP1anV2H",
        "outputId": "c5f44d32-267e-41f9-d53c-dce6e69bdd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAx88lxdg4sS",
        "outputId": "ccf06744-6ff9-495b-9ced-439a43ba074d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Soft-computing-tweet-summarization-analysis\n"
          ]
        }
      ],
      "source": [
        "#@title Set up Directory\n",
        "\n",
        "# project directory\n",
        "%cd '/content/drive/MyDrive/Soft-computing-tweet-summarization-analysis'\n",
        "\n",
        "# event datasets\n",
        "covid_tweet_dataset = \"tweetid_sentiments_emotions.csv\" #@param {type: \"string\"}\n",
        "api_keys = \"config.json\" #@param {type: \"string\"}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4z2BTPl4kl8I"
      },
      "source": [
        "# Preview Covid19 Tweet Dataset\n",
        "Repository Link:\n",
        "Covid-19 Tweet Sentiment Analysis: https://www.openicpsr.org/openicpsr/project/120321/\n",
        "\n",
        "Dataset Summary:\n",
        "\"This project aims to present a large dataset for researchers to discover public conversation on Twitter surrounding the COVID-19 pandemic. From 28 January 2020 to 1 September 2021, we collected over 198 million Twitter posts from more than 25 million unique users using four keywords: “corona”, “wuhan”, “nCov” and “covid”. Leveraging topic modeling techniques and pre-trained machine learning-based emotion analytic algorithms, we labeled each tweet with seventeen semantic attributes, including a) ten binary attributes indicating the tweet’s relevance or irrelevance to the top ten detected topics, b) five quantitative emotion attributes indicating the degree of intensity of the valence or sentiment (from 0: very negative to 1: very positive), and the degree of intensity of fear, anger, happiness and sadness emotions (from 0: not at all to 1: extremely intense), and c) two qualitative attributes indicating the sentiment category (very negative, negative, neutral or mixed, positive, very positive) and the dominant emotion category (fear, anger, happiness, sadness, no specific emotion) the tweet is mainly expressing.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jP1sQW7cAVJ7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG4lP0Jn5Iw8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "outputId": "aee5c0c2-e5cf-4bd0-8357-d6d26a43c75b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['tweet_ID', 'user_ID', 't1', 't2', 't3', 't4', 't5', 't6', 't7', 't8',\n",
            "       't9', 't10', 'valence_intensity', 'anger_intensity', 'fear_intensity',\n",
            "       'sadness_intensity', 'joy_intensity', 'sentiment_category',\n",
            "       'emotion_category', 'keyword_used', 'country_region', 'date_stamp'],\n",
            "      dtype='object')\n",
            "Length: 6166151\n",
            "Null entries: tweet_ID              0\n",
            "user_ID               0\n",
            "t1                    0\n",
            "t2                    0\n",
            "t3                    0\n",
            "t4                    0\n",
            "t5                    0\n",
            "t6                    0\n",
            "t7                    0\n",
            "t8                    0\n",
            "t9                    0\n",
            "t10                   0\n",
            "valence_intensity     0\n",
            "anger_intensity       0\n",
            "fear_intensity        0\n",
            "sadness_intensity     0\n",
            "joy_intensity         0\n",
            "sentiment_category    0\n",
            "emotion_category      0\n",
            "keyword_used          0\n",
            "country_region        0\n",
            "date_stamp            0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_ID              user_ID  t1  t2  t3  t4  t5  t6  t7  t8  \\\n",
              "0  1224743225916825600            600031424   1   0   0   0   0   0   0   0   \n",
              "1  1224742950401273858   964089407107080193   1   0   1   0   0   0   0   0   \n",
              "2  1224742938585944064             83182871   1   0   1   0   0   0   0   0   \n",
              "3  1224742733673185280  1212648845982650368   1   0   0   0   0   0   0   0   \n",
              "4  1224742511626702848   964089407107080193   1   1   0   0   0   0   0   0   \n",
              "\n",
              "   t9  t10  valence_intensity  anger_intensity  fear_intensity  \\\n",
              "0   0    0              0.466            0.462           0.575   \n",
              "1   0    0              0.402            0.491           0.468   \n",
              "2   0    0              0.662            0.329           0.390   \n",
              "3   0    0              0.522            0.387           0.486   \n",
              "4   0    0              0.436            0.435           0.465   \n",
              "\n",
              "   sadness_intensity  joy_intensity sentiment_category emotion_category  \\\n",
              "0              0.480          0.293           negative             fear   \n",
              "1              0.454          0.233           negative            anger   \n",
              "2              0.316          0.499           positive              joy   \n",
              "3              0.425          0.354           positive              joy   \n",
              "4              0.428          0.252           negative             fear   \n",
              "\n",
              "  keyword_used country_region           date_stamp  \n",
              "0        wuhan          India  2020-02-05 00:00:00  \n",
              "1        wuhan          India  2020-02-05 00:00:00  \n",
              "2        wuhan          India  2020-02-05 00:00:00  \n",
              "3        wuhan          India  2020-02-05 00:00:00  \n",
              "4        wuhan          India  2020-02-05 00:00:00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86dcf458-3a83-450c-be88-31b550400ebd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_ID</th>\n",
              "      <th>user_ID</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "      <th>t3</th>\n",
              "      <th>t4</th>\n",
              "      <th>t5</th>\n",
              "      <th>t6</th>\n",
              "      <th>t7</th>\n",
              "      <th>t8</th>\n",
              "      <th>t9</th>\n",
              "      <th>t10</th>\n",
              "      <th>valence_intensity</th>\n",
              "      <th>anger_intensity</th>\n",
              "      <th>fear_intensity</th>\n",
              "      <th>sadness_intensity</th>\n",
              "      <th>joy_intensity</th>\n",
              "      <th>sentiment_category</th>\n",
              "      <th>emotion_category</th>\n",
              "      <th>keyword_used</th>\n",
              "      <th>country_region</th>\n",
              "      <th>date_stamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1224743225916825600</td>\n",
              "      <td>600031424</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.466</td>\n",
              "      <td>0.462</td>\n",
              "      <td>0.575</td>\n",
              "      <td>0.480</td>\n",
              "      <td>0.293</td>\n",
              "      <td>negative</td>\n",
              "      <td>fear</td>\n",
              "      <td>wuhan</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-02-05 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1224742950401273858</td>\n",
              "      <td>964089407107080193</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0.491</td>\n",
              "      <td>0.468</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.233</td>\n",
              "      <td>negative</td>\n",
              "      <td>anger</td>\n",
              "      <td>wuhan</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-02-05 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1224742938585944064</td>\n",
              "      <td>83182871</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.662</td>\n",
              "      <td>0.329</td>\n",
              "      <td>0.390</td>\n",
              "      <td>0.316</td>\n",
              "      <td>0.499</td>\n",
              "      <td>positive</td>\n",
              "      <td>joy</td>\n",
              "      <td>wuhan</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-02-05 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1224742733673185280</td>\n",
              "      <td>1212648845982650368</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.522</td>\n",
              "      <td>0.387</td>\n",
              "      <td>0.486</td>\n",
              "      <td>0.425</td>\n",
              "      <td>0.354</td>\n",
              "      <td>positive</td>\n",
              "      <td>joy</td>\n",
              "      <td>wuhan</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-02-05 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1224742511626702848</td>\n",
              "      <td>964089407107080193</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.436</td>\n",
              "      <td>0.435</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.428</td>\n",
              "      <td>0.252</td>\n",
              "      <td>negative</td>\n",
              "      <td>fear</td>\n",
              "      <td>wuhan</td>\n",
              "      <td>India</td>\n",
              "      <td>2020-02-05 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86dcf458-3a83-450c-be88-31b550400ebd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86dcf458-3a83-450c-be88-31b550400ebd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86dcf458-3a83-450c-be88-31b550400ebd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#@title Covid-19 dataset preview\n",
        "covid_dataset=pd.read_csv(covid_tweet_dataset)\n",
        "print(\"Columns:\", covid_dataset.columns)\n",
        "print(\"Length:\", len(covid_dataset))\n",
        "print(\"Null entries:\", covid_dataset.isnull().sum())\n",
        "covid_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUFgFUOjcliA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "0daa1161-0980-4561-c8e2-72776f0b77c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: Index(['tweet_ID', 'sentiment_category', 'keyword_used', 'date_stamp'], dtype='object')\n",
            "Length: 10000\n",
            "Null entries: tweet_ID              0\n",
            "sentiment_category    0\n",
            "keyword_used          0\n",
            "date_stamp            0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              tweet_ID sentiment_category keyword_used           date_stamp\n",
              "0  1241702585477693441           positive        covid  2020-03-22 00:00:00\n",
              "1  1241702581795094528            neutral        covid  2020-03-22 00:00:00\n",
              "2  1241702581300158471           negative        covid  2020-03-22 00:00:00\n",
              "3  1241702577684623361           positive        covid  2020-03-22 00:00:00\n",
              "4  1241702576975835136           positive        covid  2020-03-22 00:00:00"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9c7cd39b-d339-4be6-8027-55632cc2b5e2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_ID</th>\n",
              "      <th>sentiment_category</th>\n",
              "      <th>keyword_used</th>\n",
              "      <th>date_stamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1241702585477693441</td>\n",
              "      <td>positive</td>\n",
              "      <td>covid</td>\n",
              "      <td>2020-03-22 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1241702581795094528</td>\n",
              "      <td>neutral</td>\n",
              "      <td>covid</td>\n",
              "      <td>2020-03-22 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1241702581300158471</td>\n",
              "      <td>negative</td>\n",
              "      <td>covid</td>\n",
              "      <td>2020-03-22 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1241702577684623361</td>\n",
              "      <td>positive</td>\n",
              "      <td>covid</td>\n",
              "      <td>2020-03-22 00:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1241702576975835136</td>\n",
              "      <td>positive</td>\n",
              "      <td>covid</td>\n",
              "      <td>2020-03-22 00:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c7cd39b-d339-4be6-8027-55632cc2b5e2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9c7cd39b-d339-4be6-8027-55632cc2b5e2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9c7cd39b-d339-4be6-8027-55632cc2b5e2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#@title Covid-19 subset preview\n",
        "covid_subset = pd.read_csv(covid_tweet_dataset, \n",
        "                           skiprows=range(1,540000), \n",
        "                           nrows=10000, \n",
        "                           usecols=[0,17,19,21])\n",
        "print(\"Columns:\", covid_subset.columns)\n",
        "print(\"Length:\", len(covid_subset))\n",
        "print(\"Null entries:\", covid_subset.isnull().sum())\n",
        "covid_subset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WLI2U_QpIJN"
      },
      "source": [
        "# Twitter API V2 Calls to Fetch Bulk Tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnGUFGBcBy-z"
      },
      "outputs": [],
      "source": [
        "#\n",
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDY4Bl-SsHZa"
      },
      "outputs": [],
      "source": [
        "#@title Run this cell to load your api keys\n",
        "import json\n",
        "with open(api_keys, 'r') as infile:\n",
        "  keys = json.load(infile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czL-8-9dBnVJ"
      },
      "outputs": [],
      "source": [
        "#@title Connecting to twitter using multiple accounts\n",
        "from __future__ import print_function\n",
        "import getopt\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from time import sleep\n",
        "import tweepy\n",
        "\n",
        "api = []\n",
        "for each in keys:\n",
        "  auth = tweepy.OAuthHandler(each['CONSUMER_KEY'], each['CONSUMER_SECRET'])\n",
        "  auth.set_access_token(each['OAUTH_TOKEN'], each['OAUTH_TOKEN_SECRET'])\n",
        "  api.append(tweepy.API(auth,wait_on_rate_limit=True,wait_on_rate_limit_notify=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SScpWEsu7dTC"
      },
      "outputs": [],
      "source": [
        "#@title Function to get tweets and store in csv file: get_tweets(tweet_dataframe,output_csv_file)\n",
        "def get_tweets(tweet_list,output_csv):\n",
        "  backoff_counter = 1\n",
        "  count = 0\n",
        "  HTTP_retry = 0\n",
        "  _api = api[0]\n",
        "\n",
        "  # getting full text from tweet ids\n",
        "  for each in tweet_list.tweet_ID[:]:\n",
        "    try:\n",
        "      status = _api.get_status(id=each, include_entities=False, trim_user=True, tweet_mode='extended')\n",
        "      tweet_list.at[count,'full_text'] = status.full_text\n",
        "      tweet_list.iloc[[count]].to_csv(output_csv,mode='a',header=False)\n",
        "      count+=1\n",
        "      \n",
        "      #error handle resets\n",
        "      HTTP_retry=0\n",
        "      if (count+1)%500 == 0:\n",
        "        _api = api[0]\n",
        "        print(\"Changed api\")\n",
        "      elif (count+1)%250 == 0:\n",
        "        _api = api[1]\n",
        "        print(\"Changed api\")\n",
        "        \"\"\"\n",
        "        e = tweepy.error.TweepError(api_code=429,reason=\"{'code':429,'message':'Manual rate limit reached.'}\")\n",
        "        e.args = [[{'code':429,'message':'Manual rate limit reached.'}]]\n",
        "        backoff_counter = 1;\n",
        "        raise(e)\n",
        "        \"\"\"\n",
        "    except KeyboardInterrupt:\n",
        "      print(\"Keyboard Interrupt. Done\", 100*count/len(tweet_list),\"%.\")\n",
        "      return count\n",
        "    #except tweepy.error.RateLimitError:\n",
        "      #if (count+1)%500 == 0:\n",
        "        #_api = api[0]\n",
        "        #print(\"Changed api\")\n",
        "      #elif (count+1)%250 == 0:\n",
        "        #_api = api[1]\n",
        "        #print(\"Changed api\")\n",
        "      #continue\n",
        "    except tweepy.error.TweepError as e:\n",
        "      #print(\"Done\", 100*count/len(tweet_list),\"%. Error\", e.api_code, \"-\", e.args[0][0]['message'], end=\" \")\n",
        "      if e.api_code in [34,63,144,179,401,403,404]:\n",
        "        # skipping tweet\n",
        "        count+=1\n",
        "        continue\n",
        "      elif e.api_code == 429:\n",
        "        print(\"Done\", 100*count/len(tweet_list),\"%. Error\", e.api_code, \"-\", e.args[0][0]['message'], end=\" \")\n",
        "        print(\"Waiting for\", 60*backoff_counter, \"seconds.\")\n",
        "        sleep(60*backoff_counter)\n",
        "        backoff_counter+=1\n",
        "      elif e.api_code == 4104:\n",
        "        if(HTTP_retry < 2):\n",
        "          print(\"Connection reset by peer. Retrying \", HTTP_retry, \"time.\")\n",
        "          HTTP_retry+=1\n",
        "        else:\n",
        "          print(\"Aborting due to connection error.\")\n",
        "          return count\n",
        "      else:\n",
        "        # logging unknown error\n",
        "        print(\"Done\", 100*count/len(tweet_list),\"%. Error\", e.api_code, \"-\", e.args[0][0]['message'], \"Skipping.\")\n",
        "        count+=1\n",
        "      continue\n",
        "  \n",
        "  print(\"Done\", 100*count/len(tweet_list),\"%.\")\n",
        "  \n",
        "  print(\"Processed tweet ids:\", count, \" Remaining tweets:\", len(tweet_list)-len(output))\n",
        "  return count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8p0XMz_I-93"
      },
      "source": [
        "# To get all tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eh-_jemU_F98"
      },
      "outputs": [],
      "source": [
        "#@title Making a file to save progress for continuous dataset loading, preprocessing\n",
        "!touch download_progress.json\n",
        "\n",
        "import json\n",
        "info = {'covid_last_index':0,\n",
        "        'covid_last_prep':0,\n",
        "        'covid_size':6166151,\n",
        "        'nquake_last_index':0,\n",
        "        'nquake_last_prep':0,\n",
        "        'nquake_size':100000}\n",
        "\n",
        "with open('download_progress.json', 'w') as outfile:\n",
        "     outfile.write(json.dumps(info, indent=4, sort_keys=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3-dLVOj6JWF"
      },
      "outputs": [],
      "source": [
        "#title This loop takes 2-3 days to download all tweets completely. It calls the above function to resume from last downloaded tweet.\n",
        "%mkdir -p covid_subset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# load progress\n",
        "with open('download_progress.json', 'r') as infile:\n",
        "  info = json.load(infile)\n",
        "\n",
        "print(\"Last tweet downloaded till:\", info['covid_last_index'])\n",
        "\n",
        "# load  remaining dataset\n",
        "subset = pd.read_csv(covid_tweet_dataset, skiprows=range(1,info['covid_last_index']-1))\n",
        "subset = subset.reset_index(drop=True)\n",
        "subset = subset.drop('country_region', axis=1)\n",
        "subset = subset.drop('user_ID',axis=1)\n",
        "subset = subset.iloc[:,[0,18,19]].copy()\n",
        "\n",
        "# update progress\n",
        "count = get_tweets(subset,'covid_subset/covid_subset.csv')\n",
        "info['covid_last_index'] += count\n",
        "with open('download_progress.json', 'w') as outfile:\n",
        "  outfile.write(json.dumps(info, indent=4, sort_keys=True))\n",
        "\n",
        "print(\"Dataset done\", 100*info['covid_last_index']/info['covid_size'],\"%.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvhPk0_-eNys"
      },
      "source": [
        "# To get all tweets between two dates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ltjr6XFO8QZX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#@title Grouping by dates, to see output open tweet_counts_by_dates.csv\n",
        "date_groups = pd.read_csv(covid_tweet_dataset, usecols=[0,21]).groupby('date_stamp')\n",
        "first = date_groups.get_group(list(date_groups.groups.keys())[0]).iloc[0,1][:-9]\n",
        "last = date_groups.get_group(list(date_groups.groups.keys())[len(date_groups)-1]).iloc[-1,1][:-9]\n",
        "print(first, \"and\", last)\n",
        "print('number of days:', len(date_groups))\n",
        "print('tweets\\t date\\t\\tcumulative count')\n",
        "\n",
        "count=0\n",
        "group_data = []\n",
        "for each in list(date_groups.groups.keys()):\n",
        "  count+=len(date_groups.get_group(each))\n",
        "  print(len(date_groups.get_group(each)),'\\t',date_groups.get_group(each).iloc[0,1][:-9],'\\t',count)\n",
        "  group_data.append(dict(zip(np.array(['tweets','date','tweets_till_date']),np.array([len(date_groups.get_group(each)),date_groups.get_group(each).iloc[0,1][:-9],count]))))\n",
        "\n",
        "group_df = pd.DataFrame(group_data)\n",
        "group_df.to_csv('tweet_count_by_dates.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ty146xKm9Bo"
      },
      "outputs": [],
      "source": [
        "#@title Get index range by month { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "#@markdown between 2020-01-28 and 2021-01-01\n",
        "month = 12 #@param {type:\"slider\", min:1, max:13, step:1}\n",
        "skip_days = sum([4,29,31,30,31,30,31,31,30,31,30,31,1][:month-1])\n",
        "days = [4,29,31,30,31,30,31,31,30,31,30,31,1][month-1] + skip_days\n",
        "first = date_groups.get_group(list(date_groups.groups.keys())[skip_days]).iloc[0]\n",
        "last = date_groups.get_group(list(date_groups.groups.keys())[days]).iloc[-1]\n",
        "print(\"till day\",days,\"\\nfrom\\n\",first,'\\nto\\n',last)\n",
        "skiprow=range(1,first.name)\n",
        "nrow=last.name-first.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "e0xJrlT3h9Uy"
      },
      "outputs": [],
      "source": [
        "#@title Example: fetching December 2020 dataset\n",
        "import pandas as pd\n",
        "\n",
        "count = 24700 #@param {type:\"integer\"}\n",
        "subset = pd.read_csv(covid_tweet_dataset, skiprows=range(1,5970652+count), nrows=6020498-5970652+count, usecols=[0,19,21])\n",
        "filename = \"covid_subset/7_dec_13_dec_2020.csv\" #@param {type:\"string\"}\n",
        "\n",
        "# update progress\n",
        "count += get_tweets(subset,filename)\n",
        "print(\"Dataset done\",count,\"tweets.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YS5SFgE6TKD"
      },
      "outputs": [],
      "source": [
        "#@title To check how many days of tweets were downloaded, match this output with tweet_count_by_dates.csv file\n",
        "import pandas as pd\n",
        "filename = \"covid_subset/7_dec_13_dec_2020.csv\" #@param {type:\"string\"}\n",
        "df=pd.read_csv(filename)\n",
        "df.columns=['a','b','c','date','e']\n",
        "df=df.groupby('date')\n",
        "count = 0 \n",
        "print('date_stamp\\tcount\\tcumulative_count')\n",
        "for each in df.groups.keys():\n",
        "  count+=len(df.get_group(each))\n",
        "  print(each[:-9],'\\t'+str(len(df.get_group(each))),'\\t',str(count))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns=['a','b','c','date','e']\n",
        "a=df.groupby('e')\n",
        "b=list(a.groups.keys())\n",
        "#print(a.get_group(b[len(b)-1]),'\\n---\\n',df.iloc[43688])\n",
        "df=df.drop_duplicates(subset=['e'])"
      ],
      "metadata": {
        "id": "ZX3RO3_yz2ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for each in b:\n",
        "  count+=len(a.get_group(each))\n",
        "  print(each[:-9],'\\t'+str(len(a.get_group(each))),'\\t',str(count))"
      ],
      "metadata": {
        "id": "6904eqEFDoxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2afuuZjA5oc"
      },
      "source": [
        "# To get live tweet data streams (Future Scope)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4kzWGhjm3SY"
      },
      "outputs": [],
      "source": [
        "#create streaming object and authenticate\n",
        "l = MyStreamListener()\n",
        "stream =tweepy.Stream(auth,l)\n",
        "#this line filters twiiter streams to capture data by keywords\n",
        "stream.filter(track=['covid','corona','covid19','coronavirus','facemask','sanitizer','social-distancing'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a98IYv_WkIEB"
      },
      "outputs": [],
      "source": [
        "%pip install twarc\n",
        "%pip install jsonlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRw4XkzysBVE"
      },
      "outputs": [],
      "source": [
        "#@title Insert API Keys here\n",
        "from twarc import Twarc\n",
        "\n",
        "consumer_key = \"Q7M1nSdsS8M0FjfMf2pgvE8ri\" #@param {type:\"string\"}\n",
        "consumer_secret = \"9ftWbJtiJqsRRVbPVMlkLg1haOxVg4qpoEnP6TdOxAQ9YCbPsF\" #@param {type:\"string\"}\n",
        "access_token = \"1248089353017905152-6XfrjOSINjpqudTHkdLbB6y8iFOtfa\" #@param {type:\"string\"}\n",
        "access_token_secret = \"R1DivTpuk3b7Vuo4uilXVYrmp6ZpYFYWIfFD7deukgf9u\" #@param {type:\"string\"}\n",
        "\n",
        "t = Twarc(consumer_key, consumer_secret, access_token, access_token_secret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hWvDLDrtM9K"
      },
      "outputs": [],
      "source": [
        "#@title Set up Directory\n",
        "final_tweet_ids_filename = \"tweetsidd.txt\" #@param {type: \"string\"}\n",
        "output_filename = \"output.csv\" #@param {type: \"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP1h8dtOAcLs"
      },
      "source": [
        "# Preprocess and split any datasets into train and test for ML-based methods (Future Scope)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMDWhojBDH7R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# add headers before pre-processing, do not overwrite\n",
        "tweets = pd.read_csv('covid_subset/covid_subset.csv', lineterminator='\\n', header=None)\n",
        "tweets.columns=['index','tweet_ID','keyword_used','date_stamp','full_text']\n",
        "\n",
        "# remove tweet IDs, and old index\n",
        "#tweets=tweets.drop(labels=['index','tweet_ID'], axis=1)\n",
        "\n",
        "# reset index\n",
        "tweets=tweets.reset_index()\n",
        "\n",
        "# remove duplicate entries\n",
        "#tweets=tweets.drop_duplicates(subset=['tweet_ID','full_text'], keep='first')\n",
        "\n",
        "list(tweets.full_text.head())\n",
        "\n",
        "# incomplete"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "l8p0XMz_I-93",
        "O2afuuZjA5oc",
        "mP1h8dtOAcLs"
      ],
      "name": "nltk_covid19_dataset_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}